# ğŸ’¡ Intelligent Complaint Analysis for Financial Services

This project implements an end-to-end system for analyzing customer complaints in the financial services sector using advanced Natural Language Processing (NLP) techniques. It leverages **LLMs**, **semantic search**, **RAG (Retrieval-Augmented Generation)**, and an interactive **Streamlit interface** for deployment.

## ğŸš€ Project Structure

ğŸ“¦ Root
â”œâ”€â”€ data/ # Contains raw and cleaned complaint data
â”œâ”€â”€ src/ # Core logic: retrieval, generation, UI components
â”‚ â”œâ”€â”€ retriever.py
â”‚ â”œâ”€â”€ rag_pipeline.py
â”‚ â””â”€â”€ ...
â”œâ”€â”€ evaluation/ # Evaluation scripts
â”‚ â””â”€â”€ evaluate.py
â”œâ”€â”€ streamlit_app.py # Streamlit chatbot UI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md # Project documentation

---

## âœ… Task 1: Data Cleaning and Complaint Categorization

### ğŸ¯ Objective:
Clean raw complaint data and categorize them into logical complaint types such as:
- Refund issues
- Delays in service
- Fraud/Unauthorized transactions
- Account-related problems

### âš™ï¸ Key Steps:
- Removed duplicates and null values
- Normalized text: lowercase, punctuation removal
- Used basic rule-based logic for categorization

### ğŸ“¦ Output:
Cleaned data stored in:
data/cleaned_complaints.csv


## âœ… Task 2: Vector Store and Retriever Pipeline

### ğŸ¯ Objective:
Convert complaints into vector format and set up a retriever pipeline.

### âš™ï¸ Key Steps:
- Used `LangChain`'s `RecursiveCharacterTextSplitter` to chunk long complaint narratives
- Embedded text chunks using `OpenAIEmbeddings`
- Stored embeddings in a `FAISS` vector store

### ğŸ“¦ Output:
- Vector index in `data/vector_store/`
- Retriever code in `src/retriever.py`

---

## âœ… Task 3: RAG Pipeline (Retriever + Generator)

### ğŸ¯ Objective:
Combine retrieval and generation to produce accurate, context-aware answers to user queries.

### âš™ï¸ Key Steps:
- Retrieved relevant complaint chunks from FAISS
- Constructed context-aware prompts
- Used `ChatOpenAI` to generate helpful responses

### ğŸ“¦ Output:
Full RAG pipeline implemented in:
src/rag_pipeline.py

## âœ… Task 4: Evaluation and Streamlit UI Deployment

### ğŸ¯ Objective:
Evaluate how well the system performs and make it usable through an interactive web interface.

### âš™ï¸ Key Steps:
#### ğŸ§ª Evaluation:
- Compared generated answers to reference answers using cosine similarity on embeddings
- Added scoring logic and visualizations

#### ğŸ’» Streamlit UI:
- Built a front-end chatbot using `streamlit`
- Accepts user queries and displays generated answers in real time

### ğŸ“¦ Output:
- Evaluation script: `evaluation/evaluate.py`
- UI: `streamlit_app.py`

---

## ğŸ§ª How to Evaluate the Model

Run this command in your Colab or local terminal:

python evaluation/evaluate.py
ğŸš€ How to Launch the Streamlit App
To launch the chatbot UI:

streamlit run streamlit_app.py
If you're using Colab, run:

!streamlit run streamlit_app.py --server.enableCORS false --server.enableXsrfProtection false
Then click the public URL that appears in the output.

âœ¨ Features
Real-time LLM-based answers

RAG (Retrieval-Augmented Generation)

Cosine similarity evaluation

Interactive Streamlit chatbot UI

ğŸ”§ Requirements
Install dependencies with:

pip install -r requirements.txt

