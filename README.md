# ğŸ” Intelligent Complaint Analysis for Financial Services

This project implements a **Retrieval-Augmented Generation (RAG)** chatbot system to help internal teams at CrediTrust Financial analyze and respond to customer complaints more effectively.

It combines vector-based semantic search with language models to answer questions grounded in real customer feedback.

---

## ğŸ¯ Objective

Transform unstructured complaint narratives into an intelligent assistant that helps product managers, compliance officers, and support teams query and analyze customer pain points across five product categories:

- Credit Cards  
- Personal Loans  
- Buy Now Pay Later (BNPL)  
- Savings Accounts  
- Money Transfers

---

## ğŸ§± Project Structure

.
â”œâ”€â”€ data/ # Raw and filtered complaint data
â”œâ”€â”€ notebooks/ # Exploratory and development notebooks
â”œâ”€â”€ report/ # Interim and final reports
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ utils/ # Modular utility classes
â”œâ”€â”€ vector_store/ # Serialized vector index & metadata
â””â”€â”€ README.md # Project overview (this file)

---

## âœ… Task Coverage

### Task 1: EDA and Preprocessing

- Loaded and analyzed the CFPB complaint dataset
- Filtered relevant product categories
- Cleaned and saved data to `data/filtered_complaints.csv`

### Task 2: Chunking, Embedding & Indexing

- Used LangChainâ€™s `RecursiveCharacterTextSplitter` for chunking  
- Embedded text using `all-MiniLM-L6-v2` from Sentence Transformers  
- Stored embeddings in FAISS index  
- Saved index + metadata to `vector_store/`

### Task 3+: (Upcoming)

- Implementing a retriever system and LLM-based question answering
- Creating an interactive chatbot with Streamlit/Gradio

---

## ğŸ’¡ Technologies Used

- `langchain` for text chunking
- `sentence-transformers` for semantic embedding
- `faiss-cpu` for vector similarity search
- `pandas`, `tqdm`, `pickle` for processing and saving
- `streamlit` or `gradio` for UI (in Task 4)

---

## ğŸ“ Key Files

### ğŸ”¹ `src/`
- `embedding_pipeline.py` â€“ Main runner for Task 2
- `config.py` â€“ Centralized chunking/embedding settings
- `utils/text_embedder.py` â€“ Class for chunking and embedding
- `utils/vector_indexer.py` â€“ Class for storing embeddings and metadata in FAISS

### ğŸ”¹ `vector_store/`
- `faiss_index.index` â€“ Saved FAISS vector store
- `metadata.pkl` â€“ Metadata for each embedded chunk

### ğŸ”¹ `report/`
- `interim_report.md` â€“ Strategy and findings for Tasks 1 & 2
- `final_report.md` â€“ To be completed for Tasks 3 & 4

---

## ğŸš€ How to Run Task 2

```bash
# Inside your conda or pip environment:
python src/embedding_pipeline.py